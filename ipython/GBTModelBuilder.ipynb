{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"../python/\")\n",
    "import modeling_utils as mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "from datawand.parametrization import ParamHelper\n",
    "ph = ParamHelper(\"../pipelines/EcmlTaxi.json\",sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_folder = ph.get(\"data_folder\")\n",
    "part = ph.get(\"part\")\n",
    "lat_digits = ph.get(\"lat_digits\")\n",
    "lng_digits = ph.get(\"lng_digits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data with generated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taxi_trips = pd.read_csv(\"%s/gen_train%s_lng%i_lat%i.csv\" % (data_folder, part, lng_digits, lat_digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taxi_trips_TEST = pd.read_csv(\"%s/gen_test_lng%i_lat%i.csv\" % (data_folder, lng_digits, lat_digits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude some features\n",
    "\n",
    "   * the complete route information (leaving only aggregation based features)\n",
    "   * precise time information is not needed either"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_features_from_data(df):\n",
    "    if \"POLYLINE\" in df.columns:\n",
    "        del df[\"POLYLINE\"]\n",
    "    if \"TRIP_LAT\" in df.columns:\n",
    "        del df[\"TRIP_LAT\"]\n",
    "    if \"TRIP_LNG\" in df.columns:\n",
    "        del df[\"TRIP_LNG\"]\n",
    "    if \"TRIP_ID\" in df.columns:\n",
    "        del df[\"TRIP_ID\"]\n",
    "    if \"DATE\" in df.columns:\n",
    "        del df[\"DATE\"]\n",
    "    if \"TIME\" in df.columns:\n",
    "        del df[\"TIME\"]\n",
    "    if \"TIMESTAMP\" in df.columns:\n",
    "        del df[\"TIMESTAMP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_features_from_data(taxi_trips)\n",
    "remove_features_from_data(taxi_trips_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace missing data with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fillna_with_mean(df):\n",
    "    col_means = df.mean()\n",
    "    return df.fillna(col_means,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taxi_trips = fillna_with_mean(taxi_trips)\n",
    "taxi_trips_TEST = fillna_with_mean(taxi_trips_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taxi_trips.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select features for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#base_features = ['CALL_TYPE','ORIGIN_CALL','ORIGIN_STAND','TAXI_ID','DAY_TYPE','DAY_OF_WEEK','TIME_OF_DAY','TRIP_SIZE']\n",
    "base_features = ['DAY_OF_WEEK','TIME_OF_DAY','TRIP_SIZE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lat_features, lng_features = [], []\n",
    "\n",
    "for feat in taxi_trips.columns:\n",
    "    if feat in base_features:\n",
    "        lat_features.append(feat)\n",
    "        lng_features.append(feat)\n",
    "    else:\n",
    "        if \"LAT\" in feat and feat != \"DESTINATION_LAT\" and feat != \"DESTINATION_LAT_FULL\":\n",
    "            lat_features.append(feat)\n",
    "        elif \"LNG\" in feat and feat != \"DESTINATION_LNG\" and feat != \"DESTINATION_LNG_FULL\":\n",
    "            lng_features.append(feat)\n",
    "            \n",
    "print lat_features\n",
    "print lng_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if \"DEPARTURE_LAT_FULL\" in lat_features:\n",
    "    lat_features.remove(\"DEPARTURE_LAT_FULL\")\n",
    "if \"DEPARTURE_LNG_FULL\" in lng_features:\n",
    "    lng_features.remove(\"DEPARTURE_LNG_FULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_trees = ph.get(\"num_trees\")\n",
    "depth = ph.get(\"depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train latitude learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lat_clf = GradientBoostingRegressor(n_estimators=num_trees,max_depth=depth)\n",
    "if ph.get(\"gbt_use_exact_lat\"):\n",
    "    lat_clf.fit(taxi_trips[lat_features],taxi_trips[\"DESTINATION_LAT_FULL\"])\n",
    "else:\n",
    "    lat_clf.fit(taxi_trips[lat_features],taxi_trips[\"DESTINATION_LAT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lat_importances = dict(zip(lat_features,lat_clf.feature_importances_))\n",
    "pd.DataFrame(sorted(lat_importances.items(), key=operator.itemgetter(1),reverse=True),columns=[\"name\",\"importance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train longitude learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lng_clf = GradientBoostingRegressor(n_estimators=num_trees,max_depth=depth)\n",
    "if ph.get(\"gbt_use_exact_lng\"):\n",
    "    lng_clf.fit(taxi_trips[lng_features],taxi_trips[\"DESTINATION_LNG_FULL\"])\n",
    "else:\n",
    "    lng_clf.fit(taxi_trips[lng_features],taxi_trips[\"DESTINATION_LNG\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lng_importances = dict(zip(lng_features,lng_clf.feature_importances_))\n",
    "pd.DataFrame(sorted(lng_importances.items(), key=operator.itemgetter(1),reverse=True),columns=[\"name\",\"importance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lat_imp_df = pd.DataFrame(lat_importances.items(),columns=[\"name\",\"weight\"])\n",
    "lng_imp_df = pd.DataFrame(lng_importances.items(),columns=[\"name\",\"weight\"])\n",
    "imp_df = pd.concat([lat_imp_df,lng_imp_df]).groupby(\"name\").mean()\n",
    "imp_df = pd.DataFrame(imp_df).reset_index()\n",
    "imp_df.sort_values(\"weight\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp_df.to_csv(\"%s/gbt_feature_importances%s_lng%i_lat%i.csv\"  % (data_folder, part, lng_digits, lat_digits),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from haversine import haversine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using original destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_haversine, train_pred_df = mu.eval_gbt_models(taxi_trips,lat_clf,lng_clf,lat_features,lng_features)\n",
    "test_haversine, test_pred_df = mu.eval_gbt_models(taxi_trips_TEST,lat_clf,lng_clf,lat_features,lng_features)\n",
    "print \"test: %f, train: %f (Haversine distance)\" % (test_haversine, train_haversine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if ph.get(\"export_prediction\"):\n",
    "    train_pred_df.to_csv(\"%s/gbt_model_pred_train%s_lng%i_lat%i.csv\"  % (data_folder, part, lng_digits, lat_digits),index=False)\n",
    "    test_pred_df.to_csv(\"%s/gbt_model_pred_test%s_lng%i_lat%i.csv\"  % (data_folder, part, lng_digits, lat_digits) ,index=False)\n",
    "    print(\"Predictions were exported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using rounded destination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "train_haversine, _ = mu.eval_gbt_models(taxi_trips,lat_clf,lng_clf,lat_features,lng_features,use_original_trg=False)\n",
    "test_haversine, _ = mu.eval_gbt_models(taxi_trips_TEST,lat_clf,lng_clf,lat_features,lng_features,use_original_trg=False)\n",
    "print \"test: %f, train: %f (Haversine distance)\" % (test_haversine, train_haversine)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dm-env]",
   "language": "python",
   "name": "conda-env-dm-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}